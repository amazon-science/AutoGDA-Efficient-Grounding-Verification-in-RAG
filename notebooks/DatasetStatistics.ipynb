{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6323eda7-cff9-47f9-9ff3-2aa075d5549f",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d36d1-b767-4d2a-a431-0557b805a418",
   "metadata": {},
   "source": [
    "Create a table with dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f474977-cf74-4c4c-9b2a-6ec6938efe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"]=\"false\"\n",
    "os.environ[\"AWS_REGION_NAME\"] = 'us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0ded679-e7b8-4e6d-bc1d-cd783dc42353",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68b8dda5-c77f-4072-919f-1d10f061e0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239d5f60-6398-41be-90b8-61600d1fd492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.script_utils import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63b350e4-3e7e-46a6-bdd5-ba66378ce668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1060 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2130 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1370 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1037 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data_utils import get_validation_evidence_size\n",
    "from src.utils.script_utils import get_datasets\n",
    "dsets = [(\"ragtruth\", \"QA\"), (\"ragtruth\", \"Summary\"),  (\"summedits\", \"all\"), (\"lfqa-veri\", \"all\")] #\n",
    "sz_list = []\n",
    "for ds, group in dsets:\n",
    "    ds_train, ds_test, ds_val = get_datasets(ds, group, length_limit=10000)\n",
    "    sizes_dict = {\"dataset\": ds, \"group\": group, \"train\": len(ds_train), \"test\": len(ds_test), \"val\": len(ds_val)}\n",
    "    #sizes_dict = {\"dataset\": ds, \"group\": group, \"train\": len(ds_train.df.evidence.unique()), \"test\": len(ds_test.df.evidence.unique()), \"val\": len(ds_val.df.evidence.unique())} # size of unique evidences\n",
    "    sz_list.append(sizes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb415b63-c4be-4995-8bb4-1e431acea2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>group</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ragtruth</td>\n",
       "      <td>QA</td>\n",
       "      <td>3661</td>\n",
       "      <td>875</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ragtruth</td>\n",
       "      <td>Summary</td>\n",
       "      <td>3561</td>\n",
       "      <td>900</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summedits</td>\n",
       "      <td>all</td>\n",
       "      <td>4097</td>\n",
       "      <td>1227</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lfqa-veri</td>\n",
       "      <td>all</td>\n",
       "      <td>171</td>\n",
       "      <td>65</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset    group  train  test  val\n",
       "0   ragtruth       QA   3661   875  143\n",
       "1   ragtruth  Summary   3561   900  144\n",
       "2  summedits      all   4097  1227   60\n",
       "3  lfqa-veri      all    171    65   35"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(sz_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a976f149-784a-40f0-9f0a-b5247cfd91b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1047 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_test, ds_val = get_datasets(\"ragtruth\", \"QA\", length_limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d8a31-c66e-410a-b2ea-a37607534a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
